{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "current_dir = %pwd\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '../'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from src.model_selection import continual_hyperparameter_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this part of the showcase we use continual hyperparameter selection framework [[M. De Lange et al. 2022](https://arxiv.org/pdf/1909.08383)] to validate and find the best parameters of the selected models for all MNIST datasets. We do not include other datasets since their backbone models are too expensive to train.\n",
    "\n",
    "Each model has its own set of parameters as specified in the corresponding yaml file in the hyperparameter folder and of them, only the learning rate and buffer size are used for finding the optimal plasticity, while the other are annealed with the hyperparameter_drop constant when considering the stability.\n",
    "\n",
    "The validation split is, for every dataset, of the 10% of the training set, while keeping the original augmentation function and the same seed for the split.\n",
    "Both $\\alpha$ and $\\beta$ are initially set to 1 (the latter only used in the DER++ model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential MNIST with DER\n",
    "\n",
    "We look for the best plasticity parameters among the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': [0.1, 0.05, 0.03, 0.01], 'buffer_size': [100, 200, 500]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.load_hparams('seq-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose as metric, for each task, the TIL and CIL averaged accuracy for this dataset since it can be evaluated in both settings, with a maximum drop of 3% with respect to the best accuracy.\n",
    "\n",
    "As it can be seen, the model achieves good hold-out performance metrics on the test set after the continual selection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how a low accuracy drop margin focuses on performance on the new tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.21879360079765326\n",
      "Task 0 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 99.76303317535546\n",
      "\n",
      "Epoch 1/1 - Loss: 0.197294950485229566\n",
      "Task 1 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 97.01986754966887\n",
      "\n",
      "Epoch 1/1 - Loss: 0.47033986449241646\n",
      "Task 2 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 99.20071047957371\n",
      "\n",
      "Epoch 1/1 - Loss: 0.24144992232322693\n",
      "Task 3 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 99.91789819376025\n",
      "\n",
      "Epoch 1/1 - Loss: 0.24856895208358765\n",
      "Task 4 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 98.05084745762713\n",
      "\n",
      "[[99.8108747   0.          0.          0.          0.        ]\n",
      " [99.90543735 97.2575906   0.          0.          0.        ]\n",
      " [99.62174941 86.19000979 98.29242263  0.          0.        ]\n",
      " [96.35933806 89.91185113 98.02561366 99.59718026  0.        ]\n",
      " [82.93144208 51.3712047  96.42475987 97.88519637 96.57085224]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 96.57\n",
      "Accuracy - Last Model (TIL): \t 96.57\n",
      "\n",
      "Accuracy - Average (CIL): \t 92.68\n",
      "Accuracy - Average (TIL): \t 95.00\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 85.04\n",
      "Accuracy - Full Stream (TIL): \t 91.68\n",
      "\n",
      "Forgetting (CIL): \t 16.59\n",
      "Forgetting (TIL): \t 8.29\n",
      "\n",
      "Backward Transfer (CIL): \t -16.59\n",
      "Backward Transfer (TIL): \t -8.29\n",
      "\n",
      "Forward Transfer (CIL): \t -60.88\n",
      "Forward Transfer (TIL): \t -16.49\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.1, 'best_buffer_size': 100, 'best_alpha': 1.0, 'best_beta': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continual_hyperparameter_selection('SequentialMNIST', accuracy_drop=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, if we increase the margin we expect a more stable model, meaning that the backward transfer should be higher as well as all metrics that take into account past performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.21860808134078986\n",
      "Task 0 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 99.84202211690362\n",
      "\n",
      "Epoch 1/1 - Loss: 0.34778621792793274\n",
      "Task 1 - Best LR: 0.05 - Best Buffer Size: 200 - Best Accuracy on Validation set: 96.64735099337749\n",
      "\n",
      "Epoch 1/1 - Loss: 0.44592320919036865\n",
      "Task 2 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 98.84547069271758\n",
      "\n",
      "Epoch 1/1 - Loss: 0.19618040323257446\n",
      "Task 3 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 99.67159277504105\n",
      "\n",
      "Epoch 1/1 - Loss: 0.30878353118896484\n",
      "Task 4 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 97.6271186440678\n",
      "\n",
      "[[99.85815603  0.          0.          0.          0.        ]\n",
      " [99.71631206 96.52301665  0.          0.          0.        ]\n",
      " [99.47990544 87.80607248 98.02561366  0.          0.        ]\n",
      " [99.62174941 92.65426053 98.39914621 99.6978852   0.        ]\n",
      " [97.96690307 85.45543585 97.86552828 99.09365559 97.07513868]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 97.08\n",
      "Accuracy - Last Model (TIL): \t 97.08\n",
      "\n",
      "Accuracy - Average (CIL): \t 96.62\n",
      "Accuracy - Average (TIL): \t 96.87\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 95.49\n",
      "Accuracy - Full Stream (TIL): \t 96.22\n",
      "\n",
      "Forgetting (CIL): \t 3.43\n",
      "Forgetting (TIL): \t 2.52\n",
      "\n",
      "Backward Transfer (CIL): \t -3.43\n",
      "Backward Transfer (TIL): \t -2.52\n",
      "\n",
      "Forward Transfer (CIL): \t -87.61\n",
      "Forward Transfer (TIL): \t -39.04\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.1, 'best_buffer_size': 200, 'best_alpha': 1.0, 'best_beta': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continual_hyperparameter_selection('SequentialMNIST', accuracy_drop=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential MNIST with DER++\n",
    "\n",
    "The setting is the same as for the standard DER model, but we also look for the best $\\beta$ parameter. \n",
    "\n",
    "Here, we can see a slight improvement over DER, with a better hold-out performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.24193820357322693\n",
      "Task 0 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 99.92101105845181\n",
      "\n",
      "Epoch 1/1 - Loss: 0.19866521656513214\n",
      "Task 1 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 97.26821192052981\n",
      "\n",
      "Epoch 1/1 - Loss: 0.16898572444915771\n",
      "Task 2 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 98.84547069271758\n",
      "\n",
      "Epoch 1/1 - Loss: 0.33798587322235115\n",
      "Task 3 - Best LR: 0.05 - Best Buffer Size: 200 - Best Accuracy on Validation set: 99.83579638752053\n",
      "\n",
      "Epoch 1/1 - Loss: 0.26001423597335815\n",
      "Task 4 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 97.96610169491525\n",
      "\n",
      "[[99.85815603  0.          0.          0.          0.        ]\n",
      " [99.85815603 96.08227228  0.          0.          0.        ]\n",
      " [99.85815603 86.53281097 99.30629669  0.          0.        ]\n",
      " [99.71631206 92.85014691 98.98612593 99.54682779  0.        ]\n",
      " [99.71631206 62.5367287  98.82604055 97.2306143  97.57942511]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 97.58\n",
      "Accuracy - Last Model (TIL): \t 97.58\n",
      "\n",
      "Accuracy - Average (CIL): \t 95.23\n",
      "Accuracy - Average (TIL): \t 97.30\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 91.18\n",
      "Accuracy - Full Stream (TIL): \t 97.12\n",
      "\n",
      "Forgetting (CIL): \t 9.12\n",
      "Forgetting (TIL): \t 1.69\n",
      "\n",
      "Backward Transfer (CIL): \t -9.12\n",
      "Backward Transfer (TIL): \t -1.69\n",
      "\n",
      "Forward Transfer (CIL): \t -59.63\n",
      "Forward Transfer (TIL): \t 1.75\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.1, 'best_buffer_size': 200, 'best_alpha': 0.5, 'best_beta': 0.5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continual_hyperparameter_selection('SequentialMNIST', accuracy_drop=0.1, plus_plus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted MNIST with DER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.8987474441528322\n",
      "Task 0 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 90.66666666666666\n",
      "\n",
      "Epoch 1/1 - Loss: 0.52269858121871957\n",
      "Task 1 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 91.5\n",
      "\n",
      "Epoch 1/1 - Loss: 0.48922467231750495\n",
      "Task 2 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 92.05\n",
      "\n",
      "Epoch 1/1 - Loss: 0.34915137290954595\n",
      "Task 3 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 92.95\n",
      "\n",
      "Epoch 1/1 - Loss: 0.35405570268630984\n",
      "Task 4 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 92.93333333333334\n",
      "\n",
      "Epoch 1/1 - Loss: 0.38096842169761667\n",
      "Task 5 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.28333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.32035407423973083\n",
      "Task 6 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 93.13333333333334\n",
      "\n",
      "Epoch 1/1 - Loss: 0.29441887140274055\n",
      "Task 7 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 93.15\n",
      "\n",
      "Epoch 1/1 - Loss: 0.29825419187545776\n",
      "Task 8 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.26666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.25308769941329956\n",
      "Task 9 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.28333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.25453323125839233\n",
      "Task 10 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.85\n",
      "\n",
      "Epoch 1/1 - Loss: 0.22422152757644653\n",
      "Task 11 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.76666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.31938904523849494\n",
      "Task 12 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.41666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.35517933964729315\n",
      "Task 13 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 93.0\n",
      "\n",
      "Epoch 1/1 - Loss: 0.21868675947189334\n",
      "Task 14 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.5\n",
      "\n",
      "Epoch 1/1 - Loss: 0.30593854188919074\n",
      "Task 15 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 92.9\n",
      "\n",
      "Epoch 1/1 - Loss: 0.26183637976646423\n",
      "Task 16 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.26666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.51473319530487063\n",
      "Task 17 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 92.53333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.29874989390373234\n",
      "Task 18 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.28333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.2816326320171356\n",
      "Task 19 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 91.76666666666667\n",
      "\n",
      "[[90.74 15.22  6.36 11.04  8.52  8.17 10.13 12.08  6.58 13.64 10.37 11.56\n",
      "   9.28  8.16 10.52 10.14  6.77 11.5   9.14 11.16]\n",
      " [87.6  92.17  8.25 17.58  7.89  6.39 11.47 10.2   9.03  9.84  7.32  9.75\n",
      "  12.44  8.48  8.8   9.44 10.49 11.22  9.57  9.1 ]\n",
      " [86.52 89.94 92.57 14.66  8.12 10.85 11.39 11.79  8.79  8.92  8.27 10.18\n",
      "  11.52  8.14  8.62  7.17  7.09  7.93  8.78 12.14]\n",
      " [74.03 84.05 89.6  92.7  10.16  6.02 12.92 11.07  8.9   7.42  8.67  8.15\n",
      "  10.96  8.53  7.62 10.92  5.42 10.42  6.52 10.9 ]\n",
      " [74.29 80.6  87.86 91.2  93.54  5.86 12.54 15.34 10.08  6.55  7.74 10.47\n",
      "  11.9   9.2  10.15  9.09  7.69 11.89  7.36 12.44]\n",
      " [68.17 77.72 77.01 88.69 86.5  93.28 11.94 14.32 10.19  9.07  9.96 11.78\n",
      "   8.   11.64 11.05 10.35  7.54 12.59  7.53 12.34]\n",
      " [69.64 73.32 69.06 85.44 84.66 90.78 93.54 12.71 13.42 10.78  7.72 14.62\n",
      "   9.71 11.04 11.88  9.28  7.13 12.31  6.38 13.86]\n",
      " [59.81 72.37 69.21 81.09 84.72 87.81 91.23 93.57 13.88  9.69  8.71 11.58\n",
      "   9.84 11.17 12.24  8.12  6.52 14.53  4.03 12.  ]\n",
      " [54.72 54.73 45.21 70.79 80.06 80.84 88.08 91.11 93.62  8.55 11.   10.5\n",
      "  13.18  7.99 11.56 11.53  5.98 15.96  6.86 12.64]\n",
      " [46.62 48.74 38.01 55.9  64.35 76.64 80.45 86.18 89.89 93.46  7.59 11.99\n",
      "  11.18  7.15 10.8  12.42  7.15 13.26  8.44 11.59]\n",
      " [38.7  45.55 39.1  50.99 63.05 67.27 66.54 83.99 85.03 91.66 94.09 11.74\n",
      "  12.18  8.66 11.52 11.75  8.13 11.81  9.78 10.61]\n",
      " [39.56 42.55 43.11 48.37 54.77 57.51 71.94 80.95 82.8  88.67 90.33 94.22\n",
      "  11.5   9.92 11.25 10.91  7.37 15.4  11.7  15.02]\n",
      " [35.13 42.79 28.08 47.29 48.07 51.71 59.2  73.58 77.1  81.27 88.19 92.09\n",
      "  93.44  8.71 10.57  9.91  8.26 12.62 11.79 11.26]\n",
      " [26.51 46.56 35.44 38.34 45.37 53.98 52.97 67.03 70.76 74.59 83.93 89.34\n",
      "  92.07 92.91 12.23 11.91  6.8  11.34 11.22 12.15]\n",
      " [25.43 45.5  27.96 31.9  38.32 54.44 51.43 66.19 56.85 73.   71.92 86.65\n",
      "  87.56 89.91 94.28 10.8   8.56 10.33 10.87 12.91]\n",
      " [26.61 41.07 23.39 30.34 32.81 51.73 44.93 58.01 53.02 67.54 66.89 84.71\n",
      "  81.51 84.5  91.61 93.44  6.36 10.22 10.78 11.65]\n",
      " [23.52 39.47 22.63 27.38 29.63 48.83 39.06 39.59 54.27 62.05 68.58 81.71\n",
      "  76.19 79.55 83.44 89.97 92.96 12.76  9.86 10.61]\n",
      " [18.59 31.9  22.45 27.8  24.77 40.34 25.9  32.14 43.69 42.24 55.37 65.05\n",
      "  59.6  48.62 62.52 77.68 81.76 90.9   9.04  9.29]\n",
      " [17.78 28.69 22.09 28.48 25.44 38.29 29.22 35.23 46.7  43.11 47.14 62.65\n",
      "  61.34 46.47 66.63 67.09 70.17 83.85 93.13  9.49]\n",
      " [21.19 32.02 19.29 32.15 27.68 44.07 31.43 39.08 49.22 44.16 47.52 62.32\n",
      "  56.67 40.48 63.3  60.67 62.81 80.32 86.38 91.97]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 91.97\n",
      "Accuracy - Average (DIL): \t 62.39\n",
      "Accuracy - Full Stream (DIL): \t 49.64\n",
      "Forgetting (DIL): \t 45.67\n",
      "Backward Transfer (DIL): \t -45.67\n",
      "Forward Transfer (DIL): \t 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.1, 'best_buffer_size': 100, 'best_alpha': 1.0, 'best_beta': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continual_hyperparameter_selection('PermutedMNIST', accuracy_drop=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted MNIST with DER++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.6964246034622192\n",
      "Task 0 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 91.25\n",
      "\n",
      "Epoch 1/1 - Loss: 0.59029185771942146\n",
      "Task 1 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 92.98333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.8846891522407532\n",
      "Task 2 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.03333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.5628597736358643\n",
      "Task 3 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.91666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.5331328511238098\n",
      "Task 4 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 93.4\n",
      "\n",
      "Epoch 1/1 - Loss: 0.53180593252182015\n",
      "Task 5 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.25\n",
      "\n",
      "Epoch 1/1 - Loss: 0.5902520418167114\n",
      "Task 6 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.73333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.7139091491699219\n",
      "Task 7 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 93.21666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.58072727918624885\n",
      "Task 8 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 92.86666666666666\n",
      "\n",
      "Epoch 1/1 - Loss: 0.5363775491714478\n",
      "Task 9 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.16666666666666\n",
      "\n",
      "Epoch 1/1 - Loss: 0.6384889483451843\n",
      "Task 10 - Best LR: 0.1 - Best Buffer Size: 100 - Best Accuracy on Validation set: 93.08333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.72887253761291564\n",
      "Task 11 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.23333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.6478974819183356\n",
      "Task 12 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 92.91666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.6139836907386781\n",
      "Task 13 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 92.95\n",
      "\n",
      "Epoch 1/1 - Loss: 0.5331571102142334\n",
      "Task 14 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 92.48333333333333\n",
      "\n",
      "Epoch 1/1 - Loss: 0.7786204814910889\n",
      "Task 15 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 92.25\n",
      "\n",
      "Epoch 1/1 - Loss: 0.5860716104507446\n",
      "Task 16 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 92.06666666666666\n",
      "\n",
      "Epoch 1/1 - Loss: 0.8137100934982385\n",
      "Task 17 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 93.01666666666667\n",
      "\n",
      "Epoch 1/1 - Loss: 0.7922755479812622\n",
      "Task 18 - Best LR: 0.1 - Best Buffer Size: 200 - Best Accuracy on Validation set: 92.7\n",
      "\n",
      "Epoch 1/1 - Loss: 0.7793582677841187\n",
      "Task 19 - Best LR: 0.1 - Best Buffer Size: 500 - Best Accuracy on Validation set: 92.63333333333334\n",
      "\n",
      "[[92.03  7.71 11.4  11.67 12.7   9.56  9.05 12.08  8.05 20.87  7.01  9.06\n",
      "   9.25  7.32  7.48 12.4   9.09 11.77 10.94  9.36]\n",
      " [89.96 93.44  8.59 12.77 11.54  8.08  9.53  9.79 10.68 11.6   7.83  7.31\n",
      "  11.28  6.15  7.19 14.42  8.6   6.56 11.99 11.84]\n",
      " [88.53 91.24 92.98  9.17  8.77  7.68 11.65  7.68  9.3   8.86  8.06  6.89\n",
      "  10.29  5.42  8.36 10.87  8.77  7.43 11.52 11.33]\n",
      " [84.03 90.78 92.17 94.32  7.95  8.87 11.02  8.86 10.88  7.6  11.57  9.03\n",
      "  10.99  8.13 10.02 11.44  8.54  5.27  9.37  6.19]\n",
      " [68.94 85.13 88.86 90.74 93.59 11.11  9.85 12.03 10.78 12.01  9.91  6.21\n",
      "  11.68  7.05 11.3  10.23  8.16  6.71  8.42  9.17]\n",
      " [70.53 78.48 79.54 88.43 92.24 93.94  9.8  11.75 11.77 11.99  9.96  7.47\n",
      "  12.35  8.63 13.59 11.5   8.95  7.97  9.69  6.77]\n",
      " [65.09 74.68 69.5  81.62 84.96 91.48 93.43 10.79 10.11 14.95  9.08 12.\n",
      "  12.47  8.   16.81 10.57  8.92 10.99  8.03  9.68]\n",
      " [54.76 60.84 65.51 80.25 81.37 88.19 91.25 93.99  8.75 14.61  8.28  9.31\n",
      "  10.97  6.24 11.23  6.5   9.36 10.09  8.    7.78]\n",
      " [52.16 61.79 61.13 78.88 73.53 85.   87.31 90.56 92.81 15.77 10.21 10.64\n",
      "  13.75  7.84 13.33  9.82  8.6   8.85  8.09  7.19]\n",
      " [48.34 59.56 53.07 72.35 64.63 81.54 83.88 89.46 91.01 93.76  9.41 10.25\n",
      "  12.53  7.37 13.15  7.12  7.76  7.54  8.41  9.54]\n",
      " [44.57 53.86 43.93 65.51 59.75 76.32 79.81 78.35 89.11 92.25 93.24 10.01\n",
      "  12.85  7.53 12.89  8.17 12.15  7.74 13.5   6.58]\n",
      " [39.26 44.71 44.68 63.04 57.97 67.75 69.11 76.12 83.89 88.72 89.36 93.61\n",
      "   7.55  9.39 12.58  9.97 11.77  8.06 10.7   6.45]\n",
      " [40.81 44.07 36.28 58.4  48.9  61.93 60.68 65.9  84.53 79.94 83.1  90.31\n",
      "  93.27 10.08 12.58 10.43 10.68  8.49 10.67  5.81]\n",
      " [46.8  42.94 32.45 49.16 43.69 55.36 55.77 64.19 76.14 74.83 76.36 84.47\n",
      "  90.44 92.58 13.86  9.99 11.28  9.32  9.66  4.95]\n",
      " [46.03 38.54 30.45 45.73 39.73 50.25 51.14 51.31 66.56 69.41 66.56 78.38\n",
      "  86.5  89.98 92.59 10.32 11.87 11.93  7.75  9.67]\n",
      " [42.4  37.9  27.43 34.95 26.7  35.63 38.62 43.25 53.97 59.08 53.69 75.91\n",
      "  72.6  77.95 81.12 92.6  17.05 12.94  5.74 12.13]\n",
      " [41.16 34.49 20.19 33.62 23.63 32.29 33.04 40.78 48.59 53.7  53.72 67.54\n",
      "  71.59 71.15 76.16 89.81 92.69 10.99  7.87  8.19]\n",
      " [36.01 28.28 20.38 26.66 21.08 36.23 31.03 29.67 43.55 50.76 50.14 63.33\n",
      "  56.21 62.41 75.51 85.85 88.35 92.7   7.56 12.21]\n",
      " [41.07 29.15 25.7  33.84 25.87 44.33 36.81 26.66 43.12 48.53 61.53 60.23\n",
      "  64.1  65.37 69.51 72.65 79.3  87.46 92.61  9.22]\n",
      " [37.34 28.9  30.22 33.95 18.73 33.98 29.44 20.32 36.46 39.91 45.62 49.46\n",
      "  51.89 57.82 63.16 70.72 63.12 82.71 88.42 92.92]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 92.92\n",
      "Accuracy - Average (DIL): \t 63.28\n",
      "Accuracy - Full Stream (DIL): \t 48.75\n",
      "Forgetting (DIL): \t 46.74\n",
      "Backward Transfer (DIL): \t -46.74\n",
      "Forward Transfer (DIL): \t 1.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.1, 'best_buffer_size': 500, 'best_alpha': 1.0, 'best_beta': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continual_hyperparameter_selection('PermutedMNIST', accuracy_drop=0.03, plus_plus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We can see how continual hyperparameter selection is influenced by the choice of the accuracy drop margin:\n",
    "- A higher allowed drop in accuracy preserves the stability of the model, meaning that we should get more backward transfer and less catastrophic forgetting.\n",
    "- A lower allowed drop in accuracy will lead to a more plastic model, which will be able to learn more tasks, but with a higher risk of catastrophic forgetting.\n",
    "\n",
    "We could even optimize different metrics, depending on the scenario we are dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dark-experience-replay-YCoLj02I-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
