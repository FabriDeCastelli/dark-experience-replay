{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T14:02:43.180590Z",
     "start_time": "2025-03-09T14:02:43.155333Z"
    }
   },
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "current_dir = %pwd\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '../'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from src.model_selection import continual_hyperparameter_selection\n",
    "import utils"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this part of the showcase we use the `Continual Hyperparameter Selection` framework [[M. De Lange et al. 2022](https://arxiv.org/pdf/1909.08383)] to validate and find the best parameters of the selected models for all MNIST datasets. We do not include other datasets since their backbone models are too expensive to train. \n",
    "\n",
    "Each model has its own set of parameters as specified in the corresponding yaml file in the `/hyperparameter` folder. Of them, only the learning rate and buffer size are used for finding the optimal **plasticity**, while the other are annealed with the _hyperparameter_drop_ constant when considering the **stability**.\n",
    "\n",
    "The validation split is, for every dataset, of the 10% of the training set, while keeping the original augmentation function and the same seed for the split.\n",
    "Both $\\alpha$ and $\\beta$ are initially set to 1 (the latter only used in the DER++ model).\n",
    "\n",
    "The authors of the paper suggest that most of the continual model selection methods in the literature _violate_ the constraint of not having access to old data. This brings the algorithm on being more applicable in a real world scenario, where we use the current data we have and continually perform model selection. \n",
    "\n",
    "As we have implemented, we decide to specify the buffer size in advance since tuning it automatically would bring an ulterior complexity:\n",
    "- If model selection increases it, just use the extra space for storing past samples;\n",
    "- Otherwise, we would have to choose which examples to discard. We could discard samples such that the proportion of the seen classes is uniform, or we could employ different heuristics.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters\n",
    "\n",
    "For the validated models we look for the following plasticity hyperparameters."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:45:14.636112Z",
     "start_time": "2025-03-09T13:45:14.623739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"SequentialMNIST Hyperparameters\", utils.load_hparams('seq-mnist'))\n",
    "print(\"PermutedMNIST Hyperparameters\", utils.load_hparams('perm-mnist'))\n",
    "print(\"RotatedMNIST Hyperparameters\", utils.load_hparams('rot-mnist'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialMNIST Hyperparameters {'lr': [0.1, 0.05, 0.03, 0.01]}\n",
      "PermutedMNIST Hyperparameters {'lr': [0.1, 0.05, 0.03, 0.01]}\n",
      "RotatedMNIST Hyperparameters {'lr': [0.1, 0.05, 0.03, 0.01]}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Sequential MNIST with DER"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose as metric, for each task, the TIL and CIL averaged accuracy for this dataset since it can be evaluated in both settings, with a maximum drop of 3% with respect to the best accuracy.\n",
    "\n",
    "As it can be seen, the model achieves good hold-out performance metrics on the test set after the continual selection process.\n",
    "The result of this run is $\\alpha=0.25$, meaning that the model is more plastic and needs less regularization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:45:24.598583Z",
     "start_time": "2025-03-09T13:45:14.636672Z"
    }
   },
   "source": "continual_hyperparameter_selection('SequentialMNIST', accuracy_drop=0.03)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 - Best LR: 0.1 - Best Accuracy on Validation set: 99.76\n",
      "Task 1 - Best LR: 0.05 - Best Accuracy on Validation set: 97.52\n",
      "Task 2 - Best LR: 0.03 - Best Accuracy on Validation set: 99.20\n",
      "Task 3 - Best LR: 0.1 - Best Accuracy on Validation set: 99.75\n",
      "Task 4 - Best LR: 0.01 - Best Accuracy on Validation set: 98.31\n",
      "\n",
      " ===  Accuracies on test sets - CIL === \n",
      "\n",
      "[[100.           0.           0.           0.           0.        ]\n",
      " [ 99.71631206  96.22918707   0.           0.           0.        ]\n",
      " [ 99.90543735  93.97649363  97.49199573   0.           0.        ]\n",
      " [ 99.57446809  92.70323213  90.1814301   96.37462236   0.        ]\n",
      " [ 99.8108747   91.77277179  90.50160085  94.05840886  96.41956631]]\n",
      "\n",
      " ===  Accuracies on test sets - TIL === \n",
      "\n",
      "[[100.          52.20372184  48.07897545  51.76233635  49.11749874]\n",
      " [ 99.71631206  97.35553379  55.76307364  51.76233635  49.11749874]\n",
      " [ 99.90543735  96.62095984  99.62646745  51.40986908  46.94906707]\n",
      " [ 99.57446809  95.93535749  99.2529349   99.54682779  59.50579929]\n",
      " [ 99.8108747   96.71890304  99.14621131  99.74823766  98.13414019]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 96.42\n",
      "Accuracy - Last Model (TIL): \t 98.13\n",
      "\n",
      "Accuracy - Average (CIL): \t 95.91\n",
      "Accuracy - Average (TIL): \t 98.74\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 94.51\n",
      "Accuracy - Full Stream (TIL): \t 98.71\n",
      "\n",
      "Forgetting (CIL): \t 3.49\n",
      "Forgetting (TIL): \t 0.28\n",
      "\n",
      "Backward Transfer (CIL): \t -3.49\n",
      "Backward Transfer (TIL): \t -0.28\n",
      "\n",
      "Forward Transfer (CIL): \t -76.86\n",
      "Forward Transfer (TIL): \t -22.14\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.01, 'best_alpha': 0.25, 'best_beta': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For both examples an accuracy drop of maximum 5% is reasonable since Split MNIST is an easy task."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential MNIST with DER++\n",
    "\n",
    "The setting is the same as for the standard DER model, but we also look for the best $\\beta$ parameter. \n",
    "\n",
    "Here, we can see a slight improvement over DER, with a better hold-out performance on the test sets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:45:45.154677Z",
     "start_time": "2025-03-09T13:45:33.682742Z"
    }
   },
   "source": "continual_hyperparameter_selection('SequentialMNIST', accuracy_drop=0.01, plus_plus=True)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 - Best LR: 0.03 - Best Accuracy on Validation set: 99.92\n",
      "Task 1 - Best LR: 0.05 - Best Accuracy on Validation set: 97.85\n",
      "Task 2 - Best LR: 0.01 - Best Accuracy on Validation set: 99.38\n",
      "Task 3 - Best LR: 0.1 - Best Accuracy on Validation set: 100.00\n",
      "Task 4 - Best LR: 0.01 - Best Accuracy on Validation set: 98.31\n",
      "\n",
      " ===  Accuracies on test sets - CIL === \n",
      "\n",
      "[[99.95271868  0.          0.          0.          0.        ]\n",
      " [99.76359338 97.35553379  0.          0.          0.        ]\n",
      " [99.8108747  96.03330069 98.98612593  0.          0.        ]\n",
      " [99.8108747  95.59255632 85.05869797 98.89224572  0.        ]\n",
      " [99.76359338 95.29872674 85.48559232 91.8429003  97.73071104]]\n",
      "\n",
      " ===  Accuracies on test sets - TIL === \n",
      "\n",
      "[[99.95271868 50.53868756 52.18783351 49.09365559 50.88250126]\n",
      " [99.76359338 97.94319295 52.50800427 25.93152064 49.72264246]\n",
      " [99.8108747  97.30656219 99.41302028 61.68177241 46.44478064]\n",
      " [99.8108747  96.52301665 98.71931697 99.6978852  32.87947554]\n",
      " [99.76359338 96.57198825 98.55923159 99.6978852  98.18456884]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 97.73\n",
      "Accuracy - Last Model (TIL): \t 98.18\n",
      "\n",
      "Accuracy - Average (CIL): \t 96.09\n",
      "Accuracy - Average (TIL): \t 98.78\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 94.02\n",
      "Accuracy - Full Stream (TIL): \t 98.56\n",
      "\n",
      "Forgetting (CIL): \t 5.70\n",
      "Forgetting (TIL): \t 0.60\n",
      "\n",
      "Backward Transfer (CIL): \t -5.70\n",
      "Backward Transfer (TIL): \t -0.60\n",
      "\n",
      "Forward Transfer (CIL): \t -91.62\n",
      "Forward Transfer (TIL): \t -42.21\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.01, 'best_alpha': 0.03125, 'best_beta': 0.03125}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted MNIST with DER\n",
    "\n",
    "In this case if we accept a 15% drop in accuracy, the model needs to be regularized more with $\\alpha = 1.0$. The performances are comparable with the ones already presented in the showcase with hard coded hyperparameters but with a decent increment in accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:50:05.412671Z",
     "start_time": "2025-03-09T13:45:45.155636Z"
    }
   },
   "source": "continual_hyperparameter_selection('PermutedMNIST', accuracy_drop=0.15)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 - Best LR: 0.01 - Best Accuracy on Validation set: 93.05\n",
      "Task 1 - Best LR: 0.01 - Best Accuracy on Validation set: 94.60\n",
      "Task 2 - Best LR: 0.03 - Best Accuracy on Validation set: 94.78\n",
      "Task 3 - Best LR: 0.01 - Best Accuracy on Validation set: 95.67\n",
      "Task 4 - Best LR: 0.01 - Best Accuracy on Validation set: 95.83\n",
      "Task 5 - Best LR: 0.03 - Best Accuracy on Validation set: 96.17\n",
      "Task 6 - Best LR: 0.01 - Best Accuracy on Validation set: 96.07\n",
      "Task 7 - Best LR: 0.01 - Best Accuracy on Validation set: 95.95\n",
      "Task 8 - Best LR: 0.03 - Best Accuracy on Validation set: 96.25\n",
      "Task 9 - Best LR: 0.01 - Best Accuracy on Validation set: 95.90\n",
      "Task 10 - Best LR: 0.01 - Best Accuracy on Validation set: 96.03\n",
      "Task 11 - Best LR: 0.01 - Best Accuracy on Validation set: 95.70\n",
      "Task 12 - Best LR: 0.01 - Best Accuracy on Validation set: 96.17\n",
      "Task 13 - Best LR: 0.01 - Best Accuracy on Validation set: 96.47\n",
      "Task 14 - Best LR: 0.01 - Best Accuracy on Validation set: 96.37\n",
      "Task 15 - Best LR: 0.01 - Best Accuracy on Validation set: 96.02\n",
      "Task 16 - Best LR: 0.01 - Best Accuracy on Validation set: 95.93\n",
      "Task 17 - Best LR: 0.05 - Best Accuracy on Validation set: 96.57\n",
      "Task 18 - Best LR: 0.01 - Best Accuracy on Validation set: 96.40\n",
      "Task 19 - Best LR: 0.01 - Best Accuracy on Validation set: 95.30\n",
      "\n",
      " ===  Accuracies on test sets - DIL === \n",
      "\n",
      "[[93.27 10.59  9.66 10.94 12.09  7.11  7.71 11.51  8.93 12.32 12.38  8.24\n",
      "   7.23 14.69 10.4   9.31  9.16  6.42  9.15  7.49]\n",
      " [93.05 95.1   9.22 12.14 14.23  8.58  9.95 11.79  7.89  9.99  7.79  8.76\n",
      "   7.49 12.63 12.28  9.84  9.98  8.56  7.53  4.05]\n",
      " [92.37 94.64 95.57 10.19 12.    9.86  9.31 11.11  8.73  8.28  9.47  7.27\n",
      "  11.12 14.94  9.19  9.74 10.59  7.12  6.76  6.37]\n",
      " [92.31 94.35 95.23 95.91 12.25  9.93  8.76  8.63  8.83  9.88 10.52  8.63\n",
      "  13.24 14.49 13.46 11.6  11.21  8.93  8.43  3.93]\n",
      " [91.79 93.99 94.72 95.59 96.13 10.29 10.59  9.51  8.77 12.12 12.54  9.78\n",
      "  11.81 13.53 11.79 12.88  9.11  6.96  8.67  8.8 ]\n",
      " [91.46 93.27 94.33 95.13 95.86 96.29 10.22  7.81 11.36 10.45 14.09 10.26\n",
      "   9.09 12.54 12.52 15.13  8.44  6.41  9.39 10.45]\n",
      " [90.4  92.23 93.7  94.6  95.34 95.87 96.41  9.32  9.91 10.94 13.38 10.48\n",
      "   8.62 14.37 11.31 11.88  8.26  5.81  8.92 11.12]\n",
      " [89.81 90.78 93.15 94.1  94.72 95.32 95.86 96.3   9.83  8.85 16.1  11.07\n",
      "   6.79 12.68 11.74 10.86  7.2   5.36  8.78 10.74]\n",
      " [89.1  90.08 92.33 93.6  94.45 94.93 95.54 95.73 96.14  9.52 12.71 10.64\n",
      "  10.53 11.73 13.02 10.64  7.24  6.92  9.48  9.76]\n",
      " [88.53 89.26 91.71 92.51 93.49 94.41 95.13 95.32 95.72 96.24 11.61 13.26\n",
      "   9.22 12.14 12.93  8.87  8.31  7.35  9.63  9.59]\n",
      " [88.28 87.92 90.62 92.18 92.88 94.13 94.22 94.42 94.94 95.78 96.43 11.8\n",
      "  11.88 11.39 13.71  7.83  7.7   6.98  8.13  8.04]\n",
      " [87.13 86.61 90.14 90.65 92.67 93.29 93.56 94.11 94.25 94.61 95.87 96.04\n",
      "  10.55  9.08 12.01  7.81  8.24  6.67  7.31  9.1 ]\n",
      " [85.85 84.62 89.93 90.02 92.1  92.04 92.94 93.46 93.29 94.24 95.25 95.19\n",
      "  96.32  9.77 12.52  7.33 10.22  6.01  7.83  7.79]\n",
      " [85.48 82.58 88.93 89.01 91.21 90.57 91.21 92.87 92.8  93.66 94.55 94.69\n",
      "  95.76 96.36 11.56  6.99  9.64  5.16  8.99  7.49]\n",
      " [84.68 81.11 86.72 87.88 89.39 89.33 90.79 91.34 92.47 92.92 93.16 93.79\n",
      "  94.63 95.99 96.15  6.96  9.99  5.01  9.33  7.63]\n",
      " [81.52 79.04 84.34 86.19 88.2  88.18 90.36 91.17 91.77 91.35 91.96 93.37\n",
      "  93.98 94.86 95.23 96.12  9.94  4.81 10.21  8.74]\n",
      " [81.26 76.67 83.54 83.8  86.69 86.3  87.32 89.88 88.9  90.1  90.26 91.46\n",
      "  93.04 93.84 94.21 95.07 96.1   5.13  9.76  8.14]\n",
      " [80.35 74.3  82.62 83.38 86.15 85.18 87.12 89.68 86.93 89.3  89.13 90.58\n",
      "  92.47 93.81 93.64 94.19 94.88 96.16  9.92  8.5 ]\n",
      " [78.7  71.81 81.82 81.02 83.67 84.7  86.13 87.57 85.82 88.5  88.15 89.33\n",
      "  91.13 92.5  93.   93.57 94.83 95.69 96.29  8.87]\n",
      " [78.16 69.07 80.56 79.96 83.05 80.43 84.67 85.9  83.57 87.72 87.38 87.53\n",
      "  89.37 91.58 92.11 93.11 93.44 94.94 95.86 96.09]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 96.09\n",
      "Accuracy - Average (DIL): \t 90.78\n",
      "Accuracy - Full Stream (DIL): \t 86.72\n",
      "Forgetting (DIL): \t 9.73\n",
      "Backward Transfer (DIL): \t -9.73\n",
      "Forward Transfer (DIL): \t -0.39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.01, 'best_alpha': 1.0, 'best_beta': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Rotated MNIST with DER\n",
    "\n",
    "Even in the case of this benchmark, the model need to be regularized more with $\\alpha = 1.0$ if we want a drop of 10% maximum in the accuracy."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:55:04.312509Z",
     "start_time": "2025-03-09T13:50:05.413806Z"
    }
   },
   "cell_type": "code",
   "source": "continual_hyperparameter_selection('RotatedMNIST', accuracy_drop=0.1)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 - Best LR: 0.03 - Best Accuracy on Validation set: 93.08\n",
      "Task 1 - Best LR: 0.01 - Best Accuracy on Validation set: 95.07\n",
      "Task 2 - Best LR: 0.01 - Best Accuracy on Validation set: 95.57\n",
      "Task 3 - Best LR: 0.01 - Best Accuracy on Validation set: 95.63\n",
      "Task 4 - Best LR: 0.01 - Best Accuracy on Validation set: 95.58\n",
      "Task 5 - Best LR: 0.01 - Best Accuracy on Validation set: 96.55\n",
      "Task 6 - Best LR: 0.03 - Best Accuracy on Validation set: 97.02\n",
      "Task 7 - Best LR: 0.03 - Best Accuracy on Validation set: 97.22\n",
      "Task 8 - Best LR: 0.01 - Best Accuracy on Validation set: 97.08\n",
      "Task 9 - Best LR: 0.01 - Best Accuracy on Validation set: 96.65\n",
      "Task 10 - Best LR: 0.01 - Best Accuracy on Validation set: 97.37\n",
      "Task 11 - Best LR: 0.01 - Best Accuracy on Validation set: 96.63\n",
      "Task 12 - Best LR: 0.01 - Best Accuracy on Validation set: 97.00\n",
      "Task 13 - Best LR: 0.01 - Best Accuracy on Validation set: 97.23\n",
      "Task 14 - Best LR: 0.01 - Best Accuracy on Validation set: 97.73\n",
      "Task 15 - Best LR: 0.03 - Best Accuracy on Validation set: 97.27\n",
      "Task 16 - Best LR: 0.05 - Best Accuracy on Validation set: 97.82\n",
      "Task 17 - Best LR: 0.01 - Best Accuracy on Validation set: 98.08\n",
      "Task 18 - Best LR: 0.01 - Best Accuracy on Validation set: 97.38\n",
      "Task 19 - Best LR: 0.03 - Best Accuracy on Validation set: 97.35\n",
      "\n",
      " ===  Accuracies on test sets - DIL === \n",
      "\n",
      "[[92.72 92.46 45.86 17.31 19.96 51.42 19.93 36.19 17.14 92.65 14.37 17.57\n",
      "  14.42 90.91 13.8  19.1  17.61 18.28 74.71 40.06]\n",
      " [94.7  94.75 44.99 17.32 21.66 50.29 21.56 34.17 17.38 94.64 16.4  18.53\n",
      "  14.78 92.81 15.45 19.05 18.52 18.84 74.02 38.6 ]\n",
      " [92.49 92.06 93.45 19.9  20.17 93.22 20.1  90.58 19.81 92.51 17.33 42.72\n",
      "  16.2  92.82 16.8  58.66 42.95 47.15 93.5  91.67]\n",
      " [89.03 88.68 88.65 91.54 30.3  87.17 30.6  85.64 91.3  88.83 55.58 84.5\n",
      "  82.19 88.64 59.86 80.81 84.47 82.33 87.57 86.25]\n",
      " [84.15 82.99 83.78 82.69 91.13 82.02 91.25 79.47 82.77 83.85 85.62 73.84\n",
      "  80.75 83.55 83.88 71.97 73.88 72.07 82.48 80.83]\n",
      " [88.29 87.51 94.   80.19 82.04 94.44 82.12 92.09 80.35 88.35 77.2  75.53\n",
      "  75.42 90.32 74.76 77.23 75.56 74.58 93.44 93.05]\n",
      " [83.86 82.57 88.87 79.7  94.14 89.5  94.11 85.8  79.82 83.78 87.33 70.62\n",
      "  78.97 85.32 84.9  70.87 70.56 69.88 88.11 86.77]\n",
      " [84.54 83.75 95.1  79.87 90.03 95.04 90.31 95.5  79.46 84.44 81.35 78.36\n",
      "  74.73 86.86 78.42 83.04 78.38 79.51 92.3  95.19]\n",
      " [83.72 82.65 92.36 94.   88.46 92.49 88.51 92.41 93.81 83.43 85.7  87.3\n",
      "  89.75 85.05 85.2  86.1  87.34 86.39 89.95 91.98]\n",
      " [94.58 93.84 92.7  90.01 86.1  93.17 86.25 92.12 90.1  94.9  82.19 82.98\n",
      "  84.62 94.58 81.01 82.92 83.07 81.99 93.42 91.68]\n",
      " [90.46 89.48 90.33 90.24 90.98 90.8  91.03 89.77 90.48 90.53 95.02 79.34\n",
      "  92.16 89.99 94.4  78.58 79.4  78.1  90.13 89.13]\n",
      " [89.54 88.4  91.51 93.15 86.78 91.29 86.9  92.03 93.14 89.78 90.29 94.79\n",
      "  88.11 89.19 89.   93.38 94.81 93.97 89.55 91.2 ]\n",
      " [88.19 86.85 89.59 95.16 85.99 89.6  86.22 89.85 95.16 88.25 94.15 91.72\n",
      "  95.68 87.36 94.01 88.99 91.73 90.34 87.79 89.06]\n",
      " [94.81 93.95 91.96 92.59 82.69 92.55 82.96 91.18 92.59 94.77 90.99 89.46\n",
      "  92.71 95.43 90.34 86.55 89.48 87.78 94.   90.6 ]\n",
      " [91.58 90.51 89.28 93.06 86.96 89.59 87.37 88.55 93.15 91.7  96.11 87.55\n",
      "  95.25 92.16 96.32 84.69 87.6  85.81 90.63 88.35]\n",
      " [90.64 89.43 92.36 93.09 83.94 91.56 84.3  93.11 92.98 90.68 92.39 95.04\n",
      "  92.31 91.48 92.36 95.76 95.08 94.92 90.58 92.32]\n",
      " [89.11 87.47 91.23 93.66 81.99 90.26 82.35 92.35 93.7  89.13 89.79 96.55\n",
      "  90.97 90.11 89.9  96.07 96.56 96.02 88.94 91.17]\n",
      " [88.04 86.37 91.03 93.24 80.8  90.07 81.01 92.39 93.14 88.31 88.43 96.83\n",
      "  89.8  89.09 88.27 96.42 96.83 96.79 88.28 91.34]\n",
      " [91.84 90.31 94.93 91.78 79.14 94.92 79.42 94.58 91.79 92.17 88.06 95.23\n",
      "  89.06 94.26 87.73 94.92 95.27 95.06 95.88 94.5 ]\n",
      " [90.76 88.7  96.42 90.81 78.65 96.14 79.1  96.6  90.83 91.11 87.27 94.99\n",
      "  87.86 93.21 87.32 95.24 95.01 94.87 95.63 96.69]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 96.69\n",
      "Accuracy - Average (DIL): \t 90.58\n",
      "Accuracy - Full Stream (DIL): \t 91.36\n",
      "Forgetting (DIL): \t 3.58\n",
      "Backward Transfer (DIL): \t -3.58\n",
      "Forward Transfer (DIL): \t 68.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_lr': 0.03, 'best_alpha': 1.0, 'best_beta': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We can see how continual hyperparameter selection is influenced by the choice of the accuracy drop margin:\n",
    "- A higher allowed drop in accuracy preserves the stability of the model, meaning that we should get more backward transfer and less catastrophic forgetting.\n",
    "- A lower allowed drop in accuracy will lead to a more plastic model, which will be able to learn more tasks, but with a higher risk of catastrophic forgetting.\n",
    "\n",
    "We could even optimize different metrics, depending on the scenario we are dealing with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dark-experience-replay-YCoLj02I-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
