{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8101c5f",
   "metadata": {},
   "source": [
    "# Dark Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1856204",
   "metadata": {},
   "source": "DISCLAIMER: all required algorithms have been implemented from scratch in this project, except from backbone models using PyTorch's `torch.nn` and `torch.optim` libraries, as well as loss functions."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bac585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "current_dir = %pwd\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '../'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b887d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we are going to show some running examples of the `Dark Experience Replay` method ([original paper](https://arxiv.org/pdf/2004.07211)). The documentation of all the implemented methods can be found underneath their respective files, functions and methods.\n",
    "\n",
    "## Implementation Choices\n",
    "- Every dataset has an associated model, together with its hyperparameters. For example, `SequentialMNIST` has a `SingleHeadMLP` model attached to it, with a predefined number of neurons per layer. It also has a fixed number of epochs (just one for the dataset simplicity) and a fixed batch size.\n",
    "- DER has a fixed replay batch size, fixed SGD optimizer with changeable learning rate. The replay buffer is implemented with reservoir and simply stores all the needed variables to perform the forward pass, the loss calculation and the optimization step.\n",
    "- In CIL, we store all output neurons in the replay buffer, which are going to be masked according to the task id in the metrics calculation.\n",
    "- In TIL, we store all output neurons in the replay buffer as in CIL. We could have adopted a multi-head architecture (implemented in `src/models.py`) but we decided to stick with the single head architecture + masking of all not required output neurons (based on the input task id).\n",
    "- In DIL, we use all neurons.\n",
    "\n",
    "## Metrics\n",
    "In all scenarios we compute the following metrics a matrix $R \\in [0,1]^{T \\times T}$, where $R_{ij} \\in [0,1]$ is the accuracy of the model at time $i$ on task $j$, and then we compute all the relevant metrics:\n",
    "- Average accuracy over all tasks: mean of its lower triangular matrix\n",
    "- Last model accuracy: bottom right element of the matrix\n",
    "- Full stream accuracy: mean of the last row of the matrix\n",
    "- Forgetting\n",
    "- Backward Transfer\n",
    "- Forward Transfer\n",
    "\n",
    "In DIL, we are more interested in forward and backward transfer with respect to the other since we always have all neurons available and the data is undergone a change of distribution (as in `PermutedMNIST` and `RotatedMNIST`). Instead, in CIL and TIL it is not a good metric, and we rather focus on accuracies and forgetting.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "In this notebook all hyperparameters such as learning rate, batch size, number of neurons per layer, etc. are fixed, sticking with the suggestions of the original paper. They are being validated in the `notebooks/validation.iypnb` notebook (in the same folder). The buffer size for ALL methods is set as default to 500, but it is then tuned in the other notebook.\n",
    "\n",
    "## Outline\n",
    "\n",
    "In this notebook we are going to show the following examples:\n",
    "1. DER and DER++ on `SequentialMNIST` (CIL and TIL)\n",
    "2. DER and DER++ on `PermutedMNIST` (DIL)\n",
    "3. DER and DER++ on `RotatedMNIST` (DIL)\n",
    "\n",
    "We also have provided examples on `CIFAR10`, which is in the notebook `notebooks/showcase_cifar10.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903abe04",
   "metadata": {},
   "source": [
    "# Sequential MNIST - Task and Class Incremental Learning\n",
    "\n",
    "Sequential MNIST consists of 5 tasks with respectively the classes 0-1, 2-3, 4-5, 6-7, 8-9. \n",
    "Here we train a MLP having one hidden layer with DER, and we show metrics for both the TIL and CIL scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b06ae",
   "metadata": {},
   "source": [
    "## DER\n",
    "\n",
    "In the cell output we can see the results of the metrics for both TIL and CIL scenarios:\n",
    "- CIL: we have the upper part of the accuracy matrix filled with zeros, which is reasonable since the model is not activating neurons of unseen classes, whilst it remembers the old tasks (lower part);\n",
    "- TIL: The upper part of the matrix is suggesting that we are randomly predicting one class over the two possible classes, which is expected since we haven't seen the data yet (remember this doesn't use as backbone a multi-head architecture).\n",
    "\n",
    "Forgetting and BWT are better in the TIL scenario, which is expected due to the simplicity of this task with respect to CIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0) - Training Samples: 11399\n",
      "Experience (1) - Training Samples: 10881\n",
      "Experience (2) - Training Samples: 10137\n",
      "Experience (3) - Training Samples: 10965\n",
      "Experience (4) - Training Samples: 10620\n",
      "Epoch 1/1 - Loss: 1.027967095375061\n",
      " ===  Accuracies - CIL === \n",
      "\n",
      "[[99.85815603  0.          0.          0.          0.        ]\n",
      " [99.8108747  93.38883448  0.          0.          0.        ]\n",
      " [99.76359338 85.99412341 95.94450374  0.          0.        ]\n",
      " [99.66903073 85.60235064 73.85272145 96.37462236  0.        ]\n",
      " [99.62174941 87.80607248 69.37033084 87.86505539 93.74684821]]\n",
      "\n",
      " ===  Accuracies - TIL === \n",
      "\n",
      "[[99.85815603 46.71890304 49.14621131 46.57603223 46.19263742]\n",
      " [99.8108747  94.31929481 60.24546425 49.64753273 48.91578417]\n",
      " [99.76359338 95.00489716 97.7054429  48.74118832 71.91124559]\n",
      " [99.66903073 94.07443683 97.38527215 99.34541793 66.96923853]\n",
      " [99.62174941 94.31929481 96.85165422 99.29506546 96.72213817]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 93.75\n",
      "Accuracy - Last Model (TIL): \t 96.72\n",
      "\n",
      "Accuracy - Average (CIL): \t 91.24\n",
      "Accuracy - Average (TIL): \t 97.58\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 87.68\n",
      "Accuracy - Full Stream (TIL): \t 97.36\n",
      "\n",
      "Forgetting (CIL): \t 10.23\n",
      "Forgetting (TIL): \t 0.29\n",
      "\n",
      "Backward Transfer (CIL): \t -10.23\n",
      "Backward Transfer (TIL): \t -0.29\n",
      "\n",
      "Forward Transfer (CIL): \t -63.33\n",
      "Forward Transfer (TIL): \t -7.66\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.metric.Metric at 0x129c22ed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_experiment(\n",
    "    DATASET='SequentialMNIST',\n",
    "    alpha=1.0,\n",
    "    lr=0.03\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbcda6",
   "metadata": {},
   "source": [
    "## DER++\n",
    "\n",
    "Here we evaluate the same scenario as before but with DER++. By looking at the final accuracies we can see that the model is more focusing on old tasks: we have a decrease of forgetting in the CIL scenario, which is the hardest between the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720083d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0) - Training Samples: 11399\n",
      "Experience (1) - Training Samples: 10881\n",
      "Experience (2) - Training Samples: 10137\n",
      "Experience (3) - Training Samples: 10965\n",
      "Experience (4) - Training Samples: 10620\n",
      "Epoch 1/1 - Loss: 1.1340641975402832\n",
      " ===  Accuracies - CIL === \n",
      "\n",
      "[[99.90543735  0.          0.          0.          0.        ]\n",
      " [99.71631206 90.40156709  0.          0.          0.        ]\n",
      " [99.71631206 89.37316357 94.87726788  0.          0.        ]\n",
      " [99.66903073 90.79333986 81.43009605 95.77039275  0.        ]\n",
      " [99.66903073 92.55631734 84.20490928 91.18831823 93.44427635]]\n",
      "\n",
      " ===  Accuracies - TIL === \n",
      "\n",
      "[[99.90543735 49.46131244 51.97438634 48.23766365 51.68935956]\n",
      " [99.71631206 91.77277179 55.54962647 61.83282981 48.10892587]\n",
      " [99.71631206 93.14397649 98.07897545 52.9204431  28.89561271]\n",
      " [99.66903073 94.22135162 98.29242263 99.39577039 25.97075139]\n",
      " [99.66903073 94.95592556 98.23906083 99.29506546 96.92385275]]\n",
      "\n",
      "=== Task-IL (TIL) vs Class-IL (CIL) Metrics ===\n",
      "\n",
      "Accuracy - Last Model (CIL): \t 93.44\n",
      "Accuracy - Last Model (TIL): \t 96.92\n",
      "\n",
      "Accuracy - Average (CIL): \t 93.51\n",
      "Accuracy - Average (TIL): \t 97.53\n",
      "\n",
      "Accuracy - Full Stream (CIL): \t 92.21\n",
      "Accuracy - Full Stream (TIL): \t 97.82\n",
      "\n",
      "Forgetting (CIL): \t 3.33\n",
      "Forgetting (TIL): \t -0.75\n",
      "\n",
      "Backward Transfer (CIL): \t -3.33\n",
      "Backward Transfer (TIL): \t 0.75\n",
      "\n",
      "Forward Transfer (CIL): \t -63.79\n",
      "Forward Transfer (TIL): \t -17.81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.metric.Metric at 0x129e09dd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_experiment(\n",
    "    DATASET='SequentialMNIST',\n",
    "    lr=0.03,\n",
    "    alpha=1.0,\n",
    "    beta=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69fbc80",
   "metadata": {},
   "source": [
    "# Permuted MNIST - Domain Incremental Learning\n",
    "\n",
    "This benchmark consists of 20 tasks in which we perform a random permutation of the pixels of the images. Each task therefore takes into account 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4462a0",
   "metadata": {},
   "source": [
    "## DER\n",
    "\n",
    "In this case the forward transfer is close to zero as expected since the permutations are not task dependent, but totally random. This means that the model is not capable of reusing its gained knowledge from the previous tasks to infer something never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be1738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0) - Training Samples: 54000\n",
      "Experience (1) - Training Samples: 54000\n",
      "Experience (2) - Training Samples: 54000\n",
      "Experience (3) - Training Samples: 54000\n",
      "Experience (4) - Training Samples: 54000\n",
      "Experience (5) - Training Samples: 54000\n",
      "Experience (6) - Training Samples: 54000\n",
      "Experience (7) - Training Samples: 54000\n",
      "Experience (8) - Training Samples: 54000\n",
      "Experience (9) - Training Samples: 54000\n",
      "Experience (10) - Training Samples: 54000\n",
      "Experience (11) - Training Samples: 54000\n",
      "Experience (12) - Training Samples: 54000\n",
      "Experience (13) - Training Samples: 54000\n",
      "Experience (14) - Training Samples: 54000\n",
      "Experience (15) - Training Samples: 54000\n",
      "Experience (16) - Training Samples: 54000\n",
      "Experience (17) - Training Samples: 54000\n",
      "Experience (18) - Training Samples: 54000\n",
      "Experience (19) - Training Samples: 54000\n",
      "Epoch 1/1 - Loss: 0.23940658569335938\n",
      " ===  Accuracies - DIL === \n",
      "\n",
      "[[92.1  11.26 10.04  9.63 12.07 11.65  9.18 10.16  5.75 11.95 10.91 12.44\n",
      "  11.36 11.23 11.38  7.5  10.04  9.91  7.21  9.76]\n",
      " [89.74 93.68 11.37 11.21  8.88 10.83  7.62 12.5   7.64 10.26  6.68 12.85\n",
      "   8.17  7.76 15.53  7.59  9.06  9.64 10.51  9.95]\n",
      " [88.99 93.12 94.5   9.71 10.09 12.91  8.03  8.96  6.71  8.73  7.74  9.42\n",
      "  10.47  9.17 13.42  8.45 10.19  9.   11.33 12.66]\n",
      " [87.65 92.6  93.78 94.68 10.81 11.49  8.19 12.88  6.83  8.76  9.88  8.21\n",
      "   8.47  7.75 13.99  8.72 12.18 12.13 10.26  8.57]\n",
      " [87.04 91.93 92.98 93.94 95.09 11.73  6.43 11.42  6.53  8.62 10.49  8.13\n",
      "   8.62  9.6   9.92 10.84 11.96 12.46 11.33  8.73]\n",
      " [86.26 91.25 92.8  93.9  94.65 94.53  6.25  9.6   8.11  8.23  9.27  8.47\n",
      "   9.39  7.8  12.3  12.01 14.18  9.06 11.01 13.6 ]\n",
      " [85.1  90.43 92.15 93.32 94.18 94.34 95.14 10.25  9.16  8.25  6.99  7.93\n",
      "   9.43  8.56 13.49 12.   13.29  6.53 10.17 10.96]\n",
      " [83.53 89.77 91.66 92.44 93.53 93.4  94.82 94.63  9.36 11.05  9.52  8.57\n",
      "  11.4   7.58 12.   12.18 11.63  6.78  9.66  9.95]\n",
      " [82.08 89.74 91.43 91.98 93.09 93.13 94.29 94.65 95.16 11.67  8.95  8.23\n",
      "  10.54  9.05 11.54 15.02 11.31  7.89 11.14 13.01]\n",
      " [79.48 89.16 89.92 90.75 92.44 92.71 93.61 94.22 94.85 95.    8.56 10.01\n",
      "  11.07 12.65 13.47 14.38 12.28  6.97 12.94 12.56]\n",
      " [78.44 88.29 89.38 89.93 92.03 91.97 93.31 93.76 94.29 94.19 95.04 11.65\n",
      "   9.86  9.65 11.43 13.13 10.01  7.19 11.36 13.14]\n",
      " [75.2  87.68 88.69 89.91 90.71 91.53 92.36 93.16 93.84 93.92 94.28 94.85\n",
      "   9.82 10.98 11.36 14.58 10.96  9.29  8.98 12.96]\n",
      " [73.25 87.12 87.82 89.94 89.96 90.44 91.7  92.15 93.16 92.97 94.15 94.54\n",
      "  94.25 10.94 11.53 16.92 10.08  7.25  8.82 14.22]\n",
      " [73.21 87.02 86.68 88.76 89.79 90.56 91.8  92.36 92.76 92.6  93.59 94.1\n",
      "  94.8  95.26 14.91 15.02 10.88  6.94 12.59 11.86]\n",
      " [72.12 86.15 85.53 87.61 89.88 89.74 90.99 91.87 91.92 92.37 92.89 93.48\n",
      "  94.47 94.8  94.82 13.66 11.31  7.03 10.57 11.45]\n",
      " [71.15 84.55 85.04 86.89 88.37 89.17 89.68 91.   91.29 91.83 91.78 92.97\n",
      "  93.31 94.48 94.57 95.04 10.64  7.44 13.11 11.94]\n",
      " [68.02 84.51 84.82 87.12 87.01 88.59 88.23 90.18 90.72 91.04 91.15 92.44\n",
      "  92.94 93.74 94.12 94.3  94.96  7.13 14.29 12.59]\n",
      " [65.82 83.38 84.5  86.24 87.24 88.38 87.58 89.25 90.36 90.28 91.   91.96\n",
      "  93.07 93.1  92.98 93.85 94.91 94.44 11.89 11.14]\n",
      " [64.3  82.7  83.26 85.12 85.96 87.53 86.33 88.74 89.55 88.25 89.59 91.57\n",
      "  92.67 92.58 92.37 93.34 94.44 94.42 94.97 11.94]\n",
      " [62.22 81.84 82.5  84.03 84.1  86.76 85.16 87.8  89.39 86.74 88.15 90.3\n",
      "  92.02 91.83 91.43 92.86 93.59 93.93 94.5  94.47]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 94.47\n",
      "Accuracy - Average (DIL): \t 89.98\n",
      "Accuracy - Full Stream (DIL): \t 87.68\n",
      "Forgetting (DIL): \t 7.32\n",
      "Backward Transfer (DIL): \t -7.32\n",
      "Forward Transfer (DIL): \t -0.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.metric.Metric at 0x12bd37ad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_experiment(\n",
    "    DATASET='PermutedMNIST',\n",
    "    lr=0.2,\n",
    "    alpha=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6e433",
   "metadata": {},
   "source": [
    "## DER++\n",
    "\n",
    "As in Sequential MNIST, we have an improvement of the metrics taking into account the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def070ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0) - Training Samples: 54000\n",
      "Experience (1) - Training Samples: 54000\n",
      "Experience (2) - Training Samples: 54000\n",
      "Experience (3) - Training Samples: 54000\n",
      "Experience (4) - Training Samples: 54000\n",
      "Experience (5) - Training Samples: 54000\n",
      "Experience (6) - Training Samples: 54000\n",
      "Experience (7) - Training Samples: 54000\n",
      "Experience (8) - Training Samples: 54000\n",
      "Experience (9) - Training Samples: 54000\n",
      "Experience (10) - Training Samples: 54000\n",
      "Experience (11) - Training Samples: 54000\n",
      "Experience (12) - Training Samples: 54000\n",
      "Experience (13) - Training Samples: 54000\n",
      "Experience (14) - Training Samples: 54000\n",
      "Experience (15) - Training Samples: 54000\n",
      "Experience (16) - Training Samples: 54000\n",
      "Experience (17) - Training Samples: 54000\n",
      "Experience (18) - Training Samples: 54000\n",
      "Experience (19) - Training Samples: 54000\n",
      "Epoch 1/1 - Loss: 0.2792215645313263\n",
      " ===  Accuracies - DIL === \n",
      "\n",
      "[[92.88 13.01 12.55 13.64  8.54  6.82 10.96  8.07  7.62  9.41  8.05 11.86\n",
      "  11.2  11.56  6.72 10.54  8.42  9.32  8.7  10.69]\n",
      " [91.96 94.04 10.13 15.32  9.19  9.29 10.11  7.68 10.6   7.69  9.2  11.93\n",
      "  10.19  9.78 10.6  10.86 10.05 10.31  8.27  9.1 ]\n",
      " [91.46 93.42 94.11 13.06 10.37 10.85 15.45  7.36 11.31  8.84  7.63 11.64\n",
      "   9.57 11.   11.22 13.42 11.26 12.31  6.34 10.31]\n",
      " [91.02 92.97 93.63 94.6  11.89  8.85 12.48  6.74 12.39  7.52  9.58 11.73\n",
      "   9.4   9.08  9.32 13.32 11.32  9.65  6.37  9.89]\n",
      " [90.47 92.91 93.53 94.08 94.41  8.72 12.55  8.82 10.2   8.22  9.55  9.7\n",
      "   9.83  9.26 10.52  9.85 11.97 10.68  6.21 10.04]\n",
      " [90.05 92.31 92.27 93.41 94.19 94.73 11.22  9.05 11.64 10.02  9.79  8.68\n",
      "  10.72  7.7   9.07  9.04 13.04  7.56  5.4  10.73]\n",
      " [89.41 91.92 92.34 93.42 93.69 94.34 94.97  9.42 12.19 10.32  9.7   7.4\n",
      "  10.99  7.11 10.06  7.89 12.23  7.93  4.58  9.72]\n",
      " [88.92 91.8  92.2  93.04 93.66 94.09 94.35 94.84 13.9   8.52 10.91  7.59\n",
      "  12.9   8.72 10.76 11.38 13.21  5.46  4.75  7.59]\n",
      " [87.49 90.44 91.61 92.49 92.34 92.95 94.16 94.57 92.65  9.57 10.38  9.03\n",
      "   8.43  8.59  8.45 12.38 15.53  6.9   5.46  7.6 ]\n",
      " [87.26 90.36 91.26 92.59 92.38 92.89 93.39 94.01 94.69 94.84 10.31  9.06\n",
      "   8.46  9.83 10.03 13.25 14.62  7.82  5.49  8.59]\n",
      " [86.43 89.64 90.73 91.82 91.7  92.73 93.48 92.36 93.91 94.21 94.66  9.21\n",
      "   9.5  10.68  8.28 13.64 12.36  9.43  7.33  7.62]\n",
      " [84.88 89.22 90.31 91.09 90.9  91.92 92.55 92.01 93.34 94.08 94.61 94.96\n",
      "   8.86 10.3   7.57 13.39 13.76 10.67  6.59  9.16]\n",
      " [84.05 88.87 89.57 90.92 91.09 91.33 91.56 91.65 92.58 93.51 93.95 94.62\n",
      "  94.45 11.3   8.6  12.9  12.81  9.59  7.26  6.34]\n",
      " [81.86 88.06 88.87 89.99 90.16 90.42 90.4  90.64 92.25 92.96 93.22 93.88\n",
      "  94.49 94.6   8.42 11.07 14.66  9.05  8.27  7.93]\n",
      " [80.65 87.01 88.14 89.45 89.47 89.4  89.88 90.52 91.14 92.24 92.85 93.06\n",
      "  93.87 94.45 94.18  9.16 13.72 10.69  7.32  8.54]\n",
      " [80.63 85.8  88.44 88.92 88.8  88.57 88.7  89.77 90.93 91.89 91.71 92.72\n",
      "  93.81 94.17 94.39 95.   13.34 12.39  8.27  9.16]\n",
      " [80.54 85.57 86.79 87.75 88.   87.65 87.65 88.92 90.07 91.78 90.93 92.07\n",
      "  93.57 92.71 94.08 94.57 94.92 11.46  7.51  8.61]\n",
      " [78.47 82.43 85.99 86.99 87.22 86.99 86.31 88.97 90.32 90.55 90.42 90.97\n",
      "  93.35 92.48 93.76 93.76 94.79 94.85  7.99  8.91]\n",
      " [77.28 82.57 84.85 86.02 86.02 86.81 86.94 88.69 89.51 89.6  89.59 89.69\n",
      "  92.77 92.4  93.33 92.38 94.5  94.33 94.84  8.99]\n",
      " [76.94 81.69 82.8  86.24 86.03 85.24 86.21 88.3  88.21 88.46 88.59 88.48\n",
      "  92.42 91.47 91.95 91.64 93.56 93.53 93.73 94.17]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 94.17\n",
      "Accuracy - Average (DIL): \t 90.80\n",
      "Accuracy - Full Stream (DIL): \t 88.48\n",
      "Forgetting (DIL): \t 6.27\n",
      "Backward Transfer (DIL): \t -6.27\n",
      "Forward Transfer (DIL): \t 1.07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.metric.Metric at 0x13f807ad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_experiment(\n",
    "    DATASET='PermutedMNIST',\n",
    "    lr=0.2,\n",
    "    alpha=1.0,\n",
    "    beta=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e0d2d",
   "metadata": {},
   "source": [
    "# Rotated MNIST - Domain Incremental Learning\n",
    "\n",
    "This benchmark consists of 20 task in which for each task we rotate the images by a fixed random angle. Each task therefore takes into account 10 classes.\n",
    "\n",
    "We expect the rotation not to be as impactful as the permutation, since it brings a gradual shift in the data distribution. The features are not completely scrambled as in the permuted case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53929d1",
   "metadata": {},
   "source": [
    "## DER\n",
    "\n",
    "As a result we have a good forward transfer, which is expected since the model can still use the features learned in the past to predict unseen tasks. The backward transfer is also good, which is expected since the rotation is not as impactful as the permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecba0632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0) - Training Samples: 54000\n",
      "Experience (1) - Training Samples: 54000\n",
      "Experience (2) - Training Samples: 54000\n",
      "Experience (3) - Training Samples: 54000\n",
      "Experience (4) - Training Samples: 54000\n",
      "Experience (5) - Training Samples: 54000\n",
      "Experience (6) - Training Samples: 54000\n",
      "Experience (7) - Training Samples: 54000\n",
      "Experience (8) - Training Samples: 54000\n",
      "Experience (9) - Training Samples: 54000\n",
      "Experience (10) - Training Samples: 54000\n",
      "Experience (11) - Training Samples: 54000\n",
      "Experience (12) - Training Samples: 54000\n",
      "Experience (13) - Training Samples: 54000\n",
      "Experience (14) - Training Samples: 54000\n",
      "Experience (15) - Training Samples: 54000\n",
      "Experience (16) - Training Samples: 54000\n",
      "Experience (17) - Training Samples: 54000\n",
      "Experience (18) - Training Samples: 54000\n",
      "Experience (19) - Training Samples: 54000\n",
      "Epoch 1/1 - Loss: 0.279278963804245\n",
      " ===  Accuracies - DIL === \n",
      "\n",
      "[[90.95 65.5  22.89 20.77 17.03 28.81 84.04 17.22 90.45 83.93 64.14 76.51\n",
      "  89.51 12.74 17.31 16.13 12.35 28.24 57.65 79.75]\n",
      " [89.42 94.75 52.38 39.33 18.27 75.39 93.41 18.7  84.06 70.93 94.41 59.09\n",
      "  91.25 13.66 18.99 15.65 13.78 73.54 93.72 63.09]\n",
      " [81.91 90.86 94.52 92.24 18.66 93.23 87.01 18.31 75.44 61.46 90.63 50.59\n",
      "  84.44 25.12 18.56 18.44 29.07 93.39 90.89 54.12]\n",
      " [78.59 89.45 95.54 95.73 18.04 92.94 84.05 16.73 70.12 54.83 89.1  44.57\n",
      "  81.   32.42 16.51 18.79 38.54 93.08 88.8  48.55]\n",
      " [70.16 84.6  89.91 90.09 93.81 86.68 77.04 91.6  61.27 47.92 84.13 40.96\n",
      "  72.11 74.44 91.28 92.33 71.32 86.67 82.49 43.84]\n",
      " [69.97 89.61 95.32 93.36 88.61 95.93 79.01 83.42 60.6  47.   89.58 37.55\n",
      "  72.52 65.65 82.95 85.15 62.73 95.73 90.09 41.86]\n",
      " [91.28 95.11 92.74 89.77 83.45 93.61 95.57 75.81 86.43 72.51 94.95 60.81\n",
      "  93.71 61.05 75.43 79.13 59.03 93.28 94.7  64.75]\n",
      " [82.26 92.1  90.5  87.74 94.47 91.47 91.72 94.91 74.99 56.97 91.86 46.34\n",
      "  87.54 67.24 94.68 91.82 64.14 91.38 91.26 49.92]\n",
      " [95.2  91.37 88.39 84.95 91.3  89.76 94.   90.92 95.59 91.51 90.99 85.56\n",
      "  95.39 61.4  89.97 88.31 59.1  89.42 90.13 88.2 ]\n",
      " [94.49 88.14 87.24 83.89 88.91 87.33 92.08 87.98 95.62 95.94 87.63 93.56\n",
      "  93.94 59.7  86.44 85.55 57.34 87.44 86.29 94.54]\n",
      " [94.21 96.38 89.52 84.32 87.53 93.15 95.58 86.92 94.33 92.8  96.31 87.18\n",
      "  95.07 57.77 85.53 83.5  55.76 92.74 95.81 89.54]\n",
      " [94.46 92.64 85.8  80.62 84.35 88.62 93.44 82.93 95.45 96.   92.75 96.01\n",
      "  94.39 56.21 80.75 81.07 52.4  88.16 91.45 96.19]\n",
      " [96.19 94.61 84.48 79.51 84.82 88.05 95.95 83.01 96.49 95.82 94.37 94.37\n",
      "  96.45 53.01 81.39 80.41 49.79 87.54 93.13 94.59]\n",
      " [93.99 91.91 83.91 81.94 90.44 86.32 93.6  86.86 94.52 93.46 91.55 91.39\n",
      "  94.53 95.13 84.93 92.31 94.06 85.39 90.38 91.94]\n",
      " [92.92 91.49 84.48 81.97 95.59 86.65 93.38 95.81 93.49 91.18 91.14 87.49\n",
      "  93.73 89.74 95.75 94.87 86.38 86.36 89.71 87.91]\n",
      " [92.79 90.53 83.23 79.37 96.16 85.58 92.55 95.44 93.22 91.32 90.17 87.84\n",
      "  93.41 91.61 95.08 96.58 88.   85.15 88.55 88.31]\n",
      " [91.5  88.79 82.22 81.38 93.52 83.83 91.26 92.48 91.99 90.41 88.35 86.95\n",
      "  92.14 96.05 91.86 95.12 95.76 82.93 86.41 87.88]\n",
      " [90.98 93.4  94.44 92.19 92.06 95.68 92.25 90.42 91.29 88.64 93.53 85.19\n",
      "  91.84 93.43 89.57 93.32 92.84 95.78 93.   85.49]\n",
      " [92.04 96.3  92.35 88.32 91.99 95.26 94.81 89.68 91.84 88.42 96.36 84.49\n",
      "  93.66 92.03 88.77 92.8  91.03 95.28 96.46 85.04]\n",
      " [94.51 94.45 89.79 84.9  90.06 92.8  94.29 87.88 95.37 95.77 94.46 95.59\n",
      "  94.52 90.7  86.96 91.68 89.51 93.   94.17 95.86]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 95.86\n",
      "Accuracy - Average (DIL): \t 91.00\n",
      "Accuracy - Full Stream (DIL): \t 92.31\n",
      "Forgetting (DIL): \t 3.24\n",
      "Backward Transfer (DIL): \t -3.24\n",
      "Forward Transfer (DIL): \t 68.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.metric.Metric at 0x133320590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_experiment(\n",
    "    DATASET='RotatedMNIST',\n",
    "    lr=0.2,\n",
    "    alpha=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81418155",
   "metadata": {},
   "source": [
    "##Â DER++\n",
    "\n",
    "This benchmark is less impacted by old predictions (similar performances to DER++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4c84a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0) - Training Samples: 54000\n",
      "Experience (1) - Training Samples: 54000\n",
      "Experience (2) - Training Samples: 54000\n",
      "Experience (3) - Training Samples: 54000\n",
      "Experience (4) - Training Samples: 54000\n",
      "Experience (5) - Training Samples: 54000\n",
      "Experience (6) - Training Samples: 54000\n",
      "Experience (7) - Training Samples: 54000\n",
      "Experience (8) - Training Samples: 54000\n",
      "Experience (9) - Training Samples: 54000\n",
      "Experience (10) - Training Samples: 54000\n",
      "Experience (11) - Training Samples: 54000\n",
      "Experience (12) - Training Samples: 54000\n",
      "Experience (13) - Training Samples: 54000\n",
      "Experience (14) - Training Samples: 54000\n",
      "Experience (15) - Training Samples: 54000\n",
      "Experience (16) - Training Samples: 54000\n",
      "Experience (17) - Training Samples: 54000\n",
      "Experience (18) - Training Samples: 54000\n",
      "Experience (19) - Training Samples: 54000\n",
      "Epoch 1/1 - Loss: 0.22809439897537231\n",
      " ===  Accuracies - DIL === \n",
      "\n",
      "[[92.63 84.24 84.88 84.8  13.51 12.25 33.92 20.16 24.23 82.53 17.68 20.16\n",
      "  20.16 67.6  15.09 89.59 17.65 13.46 90.75 91.61]\n",
      " [92.97 94.48 94.45 94.43 12.74 14.55 27.38 17.02 19.87 94.2  15.34 17.02\n",
      "  17.02 90.87 21.33 85.58 15.34 12.44 94.36 89.64]\n",
      " [92.9  96.17 96.1  96.12 12.67 14.52 25.24 16.72 19.13 95.83 15.09 16.72\n",
      "  16.72 93.27 21.99 83.18 15.24 12.53 95.19 88.53]\n",
      " [93.34 96.48 96.6  96.54 13.64 15.83 24.94 16.5  19.22 96.22 15.23 16.5\n",
      "  16.5  93.63 24.26 84.49 15.31 13.4  95.83 89.49]\n",
      " [86.56 90.75 91.39 91.4  93.85 90.66 29.08 40.18 30.47 90.23 66.48 40.18\n",
      "  40.18 85.46 56.37 74.13 66.31 93.39 89.65 80.6 ]\n",
      " [87.55 90.77 91.16 91.26 93.96 95.02 26.07 32.12 25.57 89.76 54.75 32.12\n",
      "  32.12 82.38 75.5  76.98 54.81 92.32 90.05 83.03]\n",
      " [87.13 88.67 89.01 89.06 89.59 90.38 94.27 86.38 91.63 87.95 74.25 86.38\n",
      "  86.38 80.29 67.04 85.24 74.49 87.63 88.49 86.09]\n",
      " [85.99 87.86 88.28 88.26 88.27 86.97 93.53 95.02 94.5  87.06 89.37 95.02\n",
      "  95.02 79.52 60.76 81.49 89.34 87.1  87.53 83.63]\n",
      " [85.5  86.67 87.26 87.19 86.67 85.92 94.85 94.68 95.77 85.75 85.77 94.68\n",
      "  94.68 77.09 60.07 82.53 85.9  85.26 86.12 83.44]\n",
      " [91.11 95.31 95.47 95.59 85.71 83.91 92.97 92.35 93.26 95.29 82.61 92.35\n",
      "  92.35 92.15 54.84 85.29 82.69 84.44 93.78 88.03]\n",
      " [87.21 93.05 92.89 92.94 88.75 84.37 91.45 95.05 93.24 93.07 95.83 95.05\n",
      "  95.05 87.76 51.57 80.36 95.82 89.07 90.02 83.5 ]\n",
      " [86.09 92.33 92.33 92.29 86.76 83.26 93.33 96.22 95.21 92.35 95.   96.22\n",
      "  96.22 86.42 51.81 80.05 95.02 87.18 89.25 82.75]\n",
      " [85.68 91.29 91.3  91.32 85.67 81.38 93.86 96.63 95.65 91.41 95.08 96.63\n",
      "  96.63 84.37 49.94 80.31 95.1  86.21 88.59 82.58]\n",
      " [86.67 95.36 95.49 95.54 83.38 79.14 91.43 94.5  93.38 95.74 92.44 94.5\n",
      "  94.5  95.77 46.17 78.7  92.45 83.05 91.74 82.31]\n",
      " [84.72 92.49 92.67 92.63 88.2  91.94 88.92 91.98 91.47 92.41 86.51 91.98\n",
      "  91.98 89.39 94.62 77.27 86.61 86.34 88.28 80.34]\n",
      " [94.84 93.91 93.77 93.76 87.02 89.67 90.92 90.91 90.58 93.69 85.6  90.91\n",
      "  90.91 89.59 91.02 95.21 85.72 84.92 94.19 95.18]\n",
      " [92.79 93.33 93.15 93.08 90.02 89.59 91.14 95.01 92.55 93.22 96.16 95.01\n",
      "  95.01 89.32 86.14 92.72 96.19 89.63 92.56 92.4 ]\n",
      " [90.25 91.69 91.76 91.73 95.65 94.98 88.8  92.74 89.86 91.49 94.93 92.74\n",
      "  92.74 86.71 84.33 89.49 94.88 95.92 90.03 89.81]\n",
      " [95.71 95.47 95.55 95.48 93.77 93.18 88.19 91.52 89.02 95.22 93.57 91.52\n",
      "  91.52 92.16 83.19 93.86 93.57 93.83 96.25 94.68]\n",
      " [96.42 94.3  94.33 94.23 92.49 91.78 89.47 91.15 89.   94.01 92.91 91.15\n",
      "  91.15 89.48 82.45 95.75 92.82 93.05 96.16 96.43]]\n",
      "\n",
      "=== Domain-IL (DIL Metrics Only) ===\n",
      "\n",
      "Accuracy - Last Model (DIL): \t 96.43\n",
      "Accuracy - Average (DIL): \t 91.76\n",
      "Accuracy - Full Stream (DIL): \t 92.43\n",
      "Forgetting (DIL): \t 3.13\n",
      "Backward Transfer (DIL): \t -3.13\n",
      "Forward Transfer (DIL): \t 70.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.metric.Metric at 0x1357f1350>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_experiment(\n",
    "    DATASET='RotatedMNIST',\n",
    "    lr=0.2,\n",
    "    alpha=1.0,\n",
    "    beta=0.5\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook we have shown the results of the `Dark Experience Replay` method on three different benchmarks. We have seen that the method is able to mitigate catastrophic forgetting and to improve the forward transfer in the case of Rotated MNIST. The DER++ variant is able to improve the results by taking into account the past tasks. The results are consistent with the original paper and the method is able to achieve state-of-the-art results on the benchmarks used in this project. \n",
    "\n",
    "Future works could explore the possibility of including more complex tasks and datasets, as well as different architectures.\n"
   ],
   "id": "d1e1580face7731c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56156f74a70dc377"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dark-experience-replay-YCoLj02I-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
